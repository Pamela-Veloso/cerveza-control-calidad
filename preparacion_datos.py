"""
PREPARACI√ìN DE DATOS PARA EL MODELO
- Feature Engineering
- Normalizaci√≥n
- Data Augmentation (SMOTE 2x)
- Train/Val/Test Split
- Generaci√≥n de Score de Calidad
- REPORTE HTML
"""

import pandas as pd
import numpy as np
import pickle
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import os
from datetime import datetime

# Crear carpetas necesarias
for folder in ['visualizaciones', 'data']:
    if not os.path.exists(folder):
        os.makedirs(folder)
        print(f"‚úÖ Carpeta '{folder}/' creada")

print("="*70)
print("üîß PREPARACI√ìN DE DATOS PARA DEEP LEARNING")
print("="*70)

# ============================================
# PASO 1: CARGAR DATOS ORIGINALES
# ============================================

print("\nüìÅ Cargando dataset original...")
df = pd.read_csv('beer.csv')
print(f"‚úÖ Dataset cargado: {df.shape[0]} registros")

# Mostrar distribuci√≥n original
print("\nüìä Distribuci√≥n original por estilo:")
dist_original = df['style'].value_counts()
print(dist_original)

# ============================================
# PASO 2: FEATURE ENGINEERING
# ============================================

print("\n" + "="*70)
print("üõ†Ô∏è FEATURE ENGINEERING - CREANDO NUEVAS VARIABLES")
print("="*70)

# Variables originales
X_original = df[['OG', 'ABV', 'pH', 'IBU']].values
y_style = df['style'].values

print("\n‚úÖ Variables originales: OG, ABV, pH, IBU")

# Crear nuevas caracter√≠sticas (ratios)
df['ABV_OG_ratio'] = df['ABV'] / df['OG']  # Eficiencia de fermentaci√≥n
df['IBU_ABV_ratio'] = df['IBU'] / df['ABV']  # Balance amargor/alcohol

print("‚úÖ Nuevas caracter√≠sticas creadas:")
print("   ‚Ä¢ ABV_OG_ratio: Eficiencia de fermentaci√≥n")
print("   ‚Ä¢ IBU_ABV_ratio: Balance amargor/alcohol")

# Estad√≠sticas de nuevas features
new_features_stats = df[['ABV_OG_ratio', 'IBU_ABV_ratio']].describe()

# Matriz de caracter√≠sticas AMPLIADA
X_features = df[['OG', 'ABV', 'pH', 'IBU', 'ABV_OG_ratio', 'IBU_ABV_ratio']].values

print(f"\nüìä Matriz de caracter√≠sticas: {X_features.shape}")
print(f"   ‚Ä¢ Variables originales: 4")
print(f"   ‚Ä¢ Variables nuevas: 2")
print(f"   ‚Ä¢ TOTAL: 6 caracter√≠sticas")

# ============================================
# PASO 3: CODIFICAR ETIQUETAS
# ============================================

print("\n" + "="*70)
print("üî¢ CODIFICACI√ìN DE ETIQUETAS")
print("="*70)

# Codificar estilos a n√∫meros
label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y_style)

print("\n‚úÖ Mapeo de estilos:")
mapeo_estilos = {}
for idx, style in enumerate(label_encoder.classes_):
    print(f"   {style} ‚Üí {idx}")
    mapeo_estilos[style] = idx

# Guardar el encoder para usar despu√©s
with open('label_encoder.pkl', 'wb') as f:
    pickle.dump(label_encoder, f)
print("\nüíæ Label encoder guardado en: label_encoder.pkl")

# ============================================
# PASO 4: GENERAR SCORE DE CALIDAD
# ============================================

print("\n" + "="*70)
print("‚≠ê GENERACI√ìN DE SCORE DE CALIDAD (0-100)")
print("="*70)

def calcular_score_calidad(row):
    """
    Calcula un score de calidad basado en qu√© tan cerca est√°n
    los par√°metros de los rangos √≥ptimos para cada estilo
    """
    style = row['style']
    
    # Rangos √≥ptimos definidos por maestros cerveceros
    # (basados en el an√°lisis exploratorio)
    optimal_ranges = {
        'Premium Lager': {
            'OG': (11.4, 12.6),
            'ABV': (3.9, 4.8),
            'pH': (3.9, 4.25),
            'IBU': (12, 14)
        },
        'IPA': {
            'OG': (13.0, 14.5),
            'ABV': (6.3, 6.98),
            'pH': (3.8, 4.5),
            'IBU': (38, 50)
        },
        'Light Lager': {
            'OG': (9.6, 10.2),
            'ABV': (2.7, 3.3),
            'pH': (3.8, 4.25),
            'IBU': (8, 10)
        }
    }
    
    ranges = optimal_ranges[style]
    scores = []
    
    # Calcular score para cada par√°metro
    for param in ['OG', 'ABV', 'pH', 'IBU']:
        value = row[param]
        min_val, max_val = ranges[param]
        center = (min_val + max_val) / 2
        range_width = max_val - min_val
        
        # Distancia al centro del rango √≥ptimo
        distance = abs(value - center)
        
        # Score: 100 si est√° en el centro, decrece con la distancia
        if min_val <= value <= max_val:
            param_score = 100 * (1 - distance / (range_width / 2))
        else:
            excess = min(distance - range_width / 2, range_width)
            param_score = max(0, 70 - (excess / range_width) * 70)
        
        scores.append(param_score)
    
    # Score final: promedio ponderado
    final_score = (
        scores[0] * 0.15 +  # OG
        scores[1] * 0.35 +  # ABV
        scores[2] * 0.15 +  # pH
        scores[3] * 0.35    # IBU
    )
    
    return final_score / 100  # Normalizar a 0-1

# Calcular score para cada registro
df['quality_score'] = df.apply(calcular_score_calidad, axis=1)

print("\n‚úÖ Score de calidad generado para todos los registros")
print(f"\nüìä Estad√≠sticas del Score de Calidad:")
quality_stats = df['quality_score'].describe()
print(quality_stats)

print("\nüìà Distribuci√≥n de scores por estilo:")
scores_por_estilo = {}
for style in df['style'].unique():
    scores = df[df['style'] == style]['quality_score']
    scores_por_estilo[style] = {
        'mean': scores.mean(),
        'min': scores.min(),
        'max': scores.max(),
        'std': scores.std()
    }
    print(f"   {style}:")
    print(f"      Media: {scores.mean():.3f}")
    print(f"      Min: {scores.min():.3f}, Max: {scores.max():.3f}")

# Gr√°fico 1: Distribuci√≥n de scores
fig1 = px.histogram(
    df,
    x='quality_score',
    nbins=30,
    title='Distribuci√≥n del Score de Calidad',
    labels={'quality_score': 'Score de Calidad'},
    color_discrete_sequence=['skyblue']
)
graph1_html = fig1.to_html(include_plotlyjs='cdn', div_id='graph1')

# Gr√°fico 2: Box plot por estilo
fig2 = px.box(
    df,
    x='style',
    y='quality_score',
    color='style',
    title='Score de Calidad por Estilo',
    labels={'quality_score': 'Score de Calidad', 'style': 'Estilo'},
    points='all'
)
graph2_html = fig2.to_html(include_plotlyjs='cdn', div_id='graph2')

# ============================================
# PASO 5: NORMALIZACI√ìN
# ============================================

print("\n" + "="*70)
print("üìè NORMALIZACI√ìN DE DATOS")
print("="*70)

# Normalizar caracter√≠sticas
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_features)

print("\n‚úÖ StandardScaler aplicado")
print(f"   Media de caracter√≠sticas normalizadas: {X_scaled.mean(axis=0).round(3)}")
print(f"   Desviaci√≥n est√°ndar: {X_scaled.std(axis=0).round(3)}")

# Guardar el scaler
with open('scaler.pkl', 'wb') as f:
    pickle.dump(scaler, f)
print("\nüíæ Scaler guardado en: scaler.pkl")

# ============================================
# PASO 6: DIVISI√ìN TRAIN/VAL/TEST
# ============================================

print("\n" + "="*70)
print("‚úÇÔ∏è DIVISI√ìN DE DATOS")
print("="*70)

# Preparar targets
y_quality = df['quality_score'].values

# Primera divisi√≥n: Train+Val (85%) y Test (15%)
X_temp, X_test, y_style_temp, y_style_test, y_quality_temp, y_quality_test = train_test_split(
    X_scaled, y_encoded, y_quality,
    test_size=0.15,
    random_state=42,
    stratify=y_encoded
)

# Segunda divisi√≥n: Train (70% del total) y Val (15% del total)
X_train, X_val, y_style_train, y_style_val, y_quality_train, y_quality_val = train_test_split(
    X_temp, y_style_temp, y_quality_temp,
    test_size=0.176,  # 15% del total = 0.176 de 85%
    random_state=42,
    stratify=y_style_temp
)

train_size = X_train.shape[0]
val_size = X_val.shape[0]
test_size = X_test.shape[0]

print(f"\n‚úÖ Divisi√≥n completada:")
print(f"   üì¶ Train: {train_size} muestras ({train_size/len(df)*100:.1f}%)")
print(f"   üì¶ Validation: {val_size} muestras ({val_size/len(df)*100:.1f}%)")
print(f"   üì¶ Test: {test_size} muestras ({test_size/len(df)*100:.1f}%)")

# Verificar balanceo
print("\nüìä Distribuci√≥n de estilos en cada conjunto:")
distribucion_splits = {}
for name, y_data in [('Train', y_style_train), ('Val', y_style_val), ('Test', y_style_test)]:
    unique, counts = np.unique(y_data, return_counts=True)
    distribucion_splits[name] = {}
    print(f"\n   {name}:")
    for style_idx, count in zip(unique, counts):
        style_name = label_encoder.classes_[style_idx]
        distribucion_splits[name][style_name] = count
        print(f"      {style_name}: {count} ({count/len(y_data)*100:.1f}%)")

# Gr√°fico 3: Distribuci√≥n de splits
split_data = []
for split_name, styles in distribucion_splits.items():
    for style, count in styles.items():
        split_data.append({'Split': split_name, 'Estilo': style, 'Cantidad': count})

df_splits = pd.DataFrame(split_data)
fig3 = px.bar(
    df_splits,
    x='Split',
    y='Cantidad',
    color='Estilo',
    title='Distribuci√≥n de Estilos por Conjunto (Antes de SMOTE)',
    barmode='group'
)
graph3_html = fig3.to_html(include_plotlyjs='cdn', div_id='graph3')

# ============================================
# PASO 7: DATA AUGMENTATION (SMOTE 2x)
# ============================================

print("\n" + "="*70)
print("üîÑ DATA AUGMENTATION CON SMOTE (2x)")
print("="*70)

train_original_size = X_train.shape[0]
print(f"\nüìä Antes de SMOTE: {train_original_size} muestras")

# Contar muestras actuales por clase
unique_train, counts_train = np.unique(y_style_train, return_counts=True)
print("\nüìä Distribuci√≥n original en Train:")
for style_idx, count in zip(unique_train, counts_train):
    style_name = label_encoder.classes_[style_idx]
    print(f"   {style_name}: {count} muestras")

# Calcular cu√°ntas muestras queremos por clase (DUPLICAR = 2x)
samples_per_class = int(train_original_size / len(unique_train) * 2)

# Crear diccionario de sampling strategy
sampling_strategy = {i: samples_per_class for i in unique_train}

print(f"\nüéØ Objetivo SMOTE 2x: {samples_per_class} muestras por clase")
print(f"   Total esperado: {samples_per_class * len(unique_train)} muestras")

# Aplicar SMOTE con estrategia personalizada
smote = SMOTE(
    sampling_strategy=sampling_strategy,
    k_neighbors=5,
    random_state=42
)

X_train_augmented, y_style_train_augmented = smote.fit_resample(
    X_train, 
    y_style_train
)

# Para el quality score, interpolamos
print("\nüîÑ Generando quality scores para muestras sint√©ticas...")
quality_scores_augmented = []
for i in range(len(y_style_train_augmented)):
    style = y_style_train_augmented[i]
    similar_indices = np.where(y_style_train == style)[0]
    
    if i < len(y_style_train):
        # Muestra original
        quality_scores_augmented.append(y_quality_train[i])
    else:
        # Muestra sint√©tica: promedio de scores similares con ruido
        similar_scores = y_quality_train[similar_indices]
        base_score = np.mean(similar_scores)
        noise = np.random.normal(0, 0.05)  # Peque√±a variaci√≥n
        quality_scores_augmented.append(np.clip(base_score + noise, 0, 1))

y_quality_train_augmented = np.array(quality_scores_augmented)

train_augmented_size = X_train_augmented.shape[0]
incremento = train_augmented_size - train_original_size

print(f"\n‚úÖ Despu√©s de SMOTE 2x: {train_augmented_size} muestras")
print(f"   Incremento: +{incremento} muestras ({incremento/train_original_size*100:.1f}%)")
print(f"   Factor de multiplicaci√≥n: {train_augmented_size/train_original_size:.2f}x")

# Verificar nuevo balanceo
print("\nüìä Distribuci√≥n despu√©s de SMOTE:")
distribucion_smote = {}
unique, counts = np.unique(y_style_train_augmented, return_counts=True)
for style_idx, count in zip(unique, counts):
    style_name = label_encoder.classes_[style_idx]
    distribucion_smote[style_name] = count
    print(f"   {style_name}: {count} ({count/len(y_style_train_augmented)*100:.1f}%)")

# Gr√°fico 4: Comparaci√≥n antes/despu√©s SMOTE
smote_comparison_data = []
for style in label_encoder.classes_:
    style_idx = mapeo_estilos[style]
    original = np.sum(y_style_train == style_idx)
    augmented = np.sum(y_style_train_augmented == style_idx)
    smote_comparison_data.append({'Estilo': style, 'Momento': 'Antes SMOTE', 'Cantidad': original})
    smote_comparison_data.append({'Estilo': style, 'Momento': 'Despu√©s SMOTE 2x', 'Cantidad': augmented})

df_smote = pd.DataFrame(smote_comparison_data)
fig4 = px.bar(
    df_smote,
    x='Estilo',
    y='Cantidad',
    color='Momento',
    title='Efecto de SMOTE 2x en el Conjunto de Entrenamiento',
    barmode='group',
    color_discrete_sequence=['#ff7f0e', '#2ca02c']
)
graph4_html = fig4.to_html(include_plotlyjs='cdn', div_id='graph4')

# ============================================
# PASO 8: GUARDAR DATOS PROCESADOS
# ============================================

print("\n" + "="*70)
print("üíæ GUARDANDO DATOS PROCESADOS")
print("="*70)

# Guardar todos los conjuntos
np.save('data/X_train.npy', X_train_augmented)
np.save('data/X_val.npy', X_val)
np.save('data/X_test.npy', X_test)

np.save('data/y_style_train.npy', y_style_train_augmented)
np.save('data/y_style_val.npy', y_style_val)
np.save('data/y_style_test.npy', y_style_test)

np.save('data/y_quality_train.npy', y_quality_train_augmented)
np.save('data/y_quality_val.npy', y_quality_val)
np.save('data/y_quality_test.npy', y_quality_test)

print("\n‚úÖ Datos guardados en carpeta 'data/':")
print("   ‚Ä¢ X_train.npy, X_val.npy, X_test.npy")
print("   ‚Ä¢ y_style_train.npy, y_style_val.npy, y_style_test.npy")
print("   ‚Ä¢ y_quality_train.npy, y_quality_val.npy, y_quality_test.npy")

# ============================================
# PASO 9: GENERAR REPORTE HTML
# ============================================

print("\n" + "="*70)
print("üìù GENERANDO REPORTE HTML")
print("="*70)

html_content = f"""
<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Reporte Preparaci√≥n de Datos</title>
    <style>
        body {{
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            max-width: 1400px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }}
        .header {{
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 40px;
            border-radius: 10px;
            text-align: center;
            margin-bottom: 30px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        }}
        .header h1 {{
            margin: 0;
            font-size: 2.5em;
        }}
        .header p {{
            margin: 10px 0 0 0;
            font-size: 1.1em;
            opacity: 0.9;
        }}
        .section {{
            background: white;
            padding: 30px;
            margin-bottom: 30px;
            border-radius: 10px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }}
        .section h2 {{
            color: #667eea;
            border-bottom: 3px solid #667eea;
            padding-bottom: 10px;
            margin-top: 0;
        }}
        .stats-grid {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }}
        .stat-card {{
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 20px;
            border-radius: 8px;
            text-align: center;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }}
        .stat-card h3 {{
            margin: 0;
            font-size: 2em;
            font-weight: bold;
        }}
        .stat-card p {{
            margin: 10px 0 0 0;
            opacity: 0.9;
        }}
        table {{
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
        }}
        th {{
            background-color: #667eea;
            color: white;
            padding: 12px;
            text-align: left;
        }}
        td {{
            padding: 12px;
            border-bottom: 1px solid #ddd;
        }}
        tr:hover {{
            background-color: #f5f5f5;
        }}
        .conclusiones {{
            background-color: #e8f4f8;
            border-left: 4px solid #667eea;
            padding: 20px;
            margin: 20px 0;
        }}
        .conclusiones h3 {{
            color: #667eea;
            margin-top: 0;
        }}
        .conclusiones ul {{
            line-height: 1.8;
        }}
        .graph-container {{
            margin: 30px 0;
        }}
        .footer {{
            text-align: center;
            color: #666;
            padding: 20px;
            margin-top: 40px;
            border-top: 2px solid #ddd;
        }}
        .highlight {{
            background-color: #fff3cd;
            border-left: 4px solid #ffc107;
            padding: 15px;
            margin: 15px 0;
        }}
    </style>
</head>
<body>
    <div class="header">
        <h1>üîß Preparaci√≥n de Datos</h1>
        <p>Sistema de Control de Calidad Cervecero</p>
        <p>Generado: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}</p>
    </div>

    <!-- RESUMEN EJECUTIVO -->
    <div class="section">
        <h2>üìä Resumen Ejecutivo</h2>
        <div class="stats-grid">
            <div class="stat-card">
                <h3>6</h3>
                <p>Features Totales</p>
            </div>
            <div class="stat-card">
                <h3>{train_augmented_size}</h3>
                <p>Muestras de Entrenamiento</p>
            </div>
            <div class="stat-card">
                <h3>{val_size}</h3>
                <p>Muestras de Validaci√≥n</p>
            </div>
            <div class="stat-card">
                <h3>{test_size}</h3>
                <p>Muestras de Prueba</p>
            </div>
        </div>

        <div class="highlight">
            <strong>üéØ Data Augmentation Aplicado:</strong> SMOTE 2x duplic√≥ el dataset de entrenamiento
            de {train_original_size} a {train_augmented_size} muestras (+{incremento} sint√©ticas).
            Esto mejorar√° significativamente la capacidad de generalizaci√≥n del modelo.
        </div>
    </div>

    <!-- FEATURE ENGINEERING -->
    <div class="section">
        <h2>üõ†Ô∏è Feature Engineering</h2>
        
        <div class="conclusiones">
            <h3>‚úÖ Variables Originales (4):</h3>
            <ul>
                <li><strong>OG</strong> (Original Gravity): Densidad inicial del mosto</li>
                <li><strong>ABV</strong> (Alcohol By Volume): Porcentaje de alcohol</li>
                <li><strong>pH</strong>: Nivel de acidez</li>
                <li><strong>IBU</strong> (International Bitterness Units): Amargor</li>
            </ul>
        </div>

        <div class="conclusiones">
            <h3>üÜï Variables Creadas (2):</h3>
            <ul>
                <li><strong>ABV_OG_ratio</strong>: Eficiencia de fermentaci√≥n (ABV/OG)</li>
                <li><strong>IBU_ABV_ratio</strong>: Balance entre amargor y alcohol (IBU/ABV)</li>
            </ul>
        </div>

        <table>
            <tr>
                <th>Estad√≠stica</th>
                <th>ABV_OG_ratio</th>
                <th>IBU_ABV_ratio</th>
            </tr>
            <tr>
                <td>Media</td>
                <td>{new_features_stats.loc['mean', 'ABV_OG_ratio']:.4f}</td>
                <td>{new_features_stats.loc['mean', 'IBU_ABV_ratio']:.4f}</td>
            </tr>
            <tr>
                <td>Desv. Est√°ndar</td>
                <td>{new_features_stats.loc['std', 'ABV_OG_ratio']:.4f}</td>
                <td>{new_features_stats.loc['std', 'IBU_ABV_ratio']:.4f}</td>
            </tr>
            <tr>
                <td>M√≠nimo</td>
                <td>{new_features_stats.loc['min', 'ABV_OG_ratio']:.4f}</td>
                <td>{new_features_stats.loc['min', 'IBU_ABV_ratio']:.4f}</td>
            </tr>
            <tr>
                <td>M√°ximo</td>
                <td>{new_features_stats.loc['max', 'ABV_OG_ratio']:.4f}</td>
                <td>{new_features_stats.loc['max', 'IBU_ABV_ratio']:.4f}</td>
            </tr>
        </table>
    </div>

    <!-- SCORE DE CALIDAD -->
    <div class="section">
        <h2>‚≠ê Score de Calidad</h2>
        
        <div class="conclusiones">
            <h3>üí° ¬øC√≥mo se calcula?</h3>
            <p>El score de calidad (0-1) se calcula midiendo qu√© tan cerca est√°n los par√°metros 
            de los rangos √≥ptimos para cada estilo, con los siguientes pesos:</p>
            <ul>
                <li><strong>OG:</strong> 15% del score</li>
                <li><strong>ABV:</strong> 35% del score (CR√çTICO)</li>
                <li><strong>pH:</strong> 15% del score</li>
                <li><strong>IBU:</strong> 35% del score (CR√çTICO)</li>
            </ul>
        </div>

        <table>
            <tr>
                <th>Estilo</th>
                <th>Score Promedio</th>
                <th>Score M√≠nimo</th>
                <th>Score M√°ximo</th>
                <th>Desv. Est√°ndar</th>
            </tr>
            {''.join([f'''<tr>
                <td>{style}</td>
                <td>{scores_por_estilo[style]["mean"]:.3f}</td>
                <td>{scores_por_estilo[style]["min"]:.3f}</td>
                <td>{scores_por_estilo[style]["max"]:.3f}</td>
                <td>{scores_por_estilo[style]["std"]:.3f}</td>
            </tr>''' for style in label_encoder.classes_])}
        </table>

        <div class="graph-container">
            {graph1_html}
        </div>

        <div class="graph-container">
            {graph2_html}
        </div>
    </div>

    <!-- NORMALIZACI√ìN -->
    <div class="section">
        <h2>üìè Normalizaci√≥n de Datos</h2>
        
        <div class="conclusiones">
            <h3>‚úÖ StandardScaler Aplicado</h3>
            <p>Se aplic√≥ StandardScaler para normalizar todas las caracter√≠sticas a media 0 y desviaci√≥n est√°ndar 1.</p>
            <p>Esto es crucial para redes neuronales porque:</p>
            <ul>
                <li>Acelera la convergencia del entrenamiento</li>
                <li>Evita que variables con rangos grandes dominen el aprendizaje</li>
                <li>Mejora la estabilidad num√©rica</li>
                <li>Permite que todos los features contribuyan equitativamente</li>
            </ul>
        </div>
    </div>

    <!-- DIVISI√ìN DE DATOS -->
    <div class="section">
        <h2>‚úÇÔ∏è Divisi√≥n de Datos</h2>
        
        <div class="stats-grid">
            <div class="stat-card">
                <h3>{train_original_size}</h3>
                <p>Train Original (70%)</p>
            </div>
            <div class="stat-card">
                <h3>{val_size}</h3>
                <p>Validation (15%)</p>
            </div>
            <div class="stat-card">
                <h3>{test_size}</h3>
                <p>Test (15%)</p>
            </div>
        </div>

        <div class="graph-container">
            {graph3_html}
        </div>

        <div class="conclusiones">
            <h3>üìä Estrategia de Divisi√≥n:</h3>
            <ul>
                <li><strong>Train:</strong> Para entrenar el modelo (se le aplicar√° SMOTE)</li>
                <li><strong>Validation:</strong> Para ajustar hiperpar√°metros y evitar overfitting</li>
                <li><strong>Test:</strong> Para evaluaci√≥n final (nunca visto por el modelo)</li>
                <li><strong>Divisi√≥n estratificada:</strong> Mantiene proporci√≥n de estilos en cada conjunto</li>
            </ul>
        </div>
    </div>

    <!-- DATA AUGMENTATION -->
    <div class="section">
        <h2>üîÑ Data Augmentation con SMOTE 2x</h2>
        
        <div class="stats-grid">
            <div class="stat-card">
                <h3>{train_original_size}</h3>
                <p>Antes de SMOTE</p>
            </div>
            <div class="stat-card">
                <h3>{train_augmented_size}</h3>
                <p>Despu√©s de SMOTE</p>
            </div>
            <div class="stat-card">
                <h3>+{incremento}</h3>
                <p>Muestras Generadas</p>
            </div>
            <div class="stat-card">
                <h3>{train_augmented_size/train_original_size:.2f}x</h3>
                <p>Factor Multiplicador</p>
            </div>
        </div>

        <div class="graph-container">
            {graph4_html}
        </div>

        <div class="conclusiones">
            <h3>üí° ¬øQu√© es SMOTE?</h3>
            <p><strong>SMOTE (Synthetic Minority Over-sampling Technique)</strong> genera nuevas muestras sint√©ticas 
            interpolando entre muestras existentes del mismo estilo.</p>
            <p><strong>Beneficios de SMOTE 2x:</strong></p>
            <ul>
                <li>‚úÖ <strong>Duplica el dataset de entrenamiento</strong> de {train_original_size} a {train_augmented_size} muestras</li>
                <li>‚úÖ <strong>Reduce overfitting:</strong> M√°s datos = mejor generalizaci√≥n</li>
                <li>‚úÖ <strong>Mantiene el balance:</strong> Cada estilo tiene el mismo n√∫mero de muestras</li>
                <li>‚úÖ <strong>Mejora la robustez:</strong> El modelo aprende de m√°s variaciones</li>
                <li>‚úÖ <strong>Est√°ndar de la industria:</strong> Pr√°ctica com√∫n con datasets peque√±os</li>
            </ul>
        </div>

        <div class="highlight">
            <strong>‚ö†Ô∏è Importante:</strong> SMOTE solo se aplica al conjunto de ENTRENAMIENTO. 
            Los conjuntos de validaci√≥n y test se mantienen con datos 100% originales para 
            evaluar correctamente la capacidad de generalizaci√≥n del modelo.
        </div>
    </div>

    <!-- ARCHIVOS GENERADOS -->
    <div class="section">
        <h2>üíæ Archivos Generados</h2>
        
        <table>
            <tr>
                <th>Archivo</th>
                <th>Descripci√≥n</th>
                <th>Dimensiones</th>
            </tr>
            <tr>
                <td><strong>scaler.pkl</strong></td>
                <td>StandardScaler entrenado</td>
                <td>Para normalizar nuevos datos</td>
            </tr>
            <tr>
                <td><strong>label_encoder.pkl</strong></td>
                <td>Codificador de estilos</td>
                <td>Mapeo: estilo ‚Üî n√∫mero</td>
            </tr>
            <tr>
                <td><strong>data/X_train.npy</strong></td>
                <td>Caracter√≠sticas de entrenamiento (CON SMOTE)</td>
                <td>{train_augmented_size} √ó 6</td>
            </tr>
            <tr>
                <td><strong>data/X_val.npy</strong></td>
                <td>Caracter√≠sticas de validaci√≥n (ORIGINAL)</td>
                <td>{val_size} √ó 6</td>
            </tr>
            <tr>
                <td><strong>data/X_test.npy</strong></td>
                <td>Caracter√≠sticas de prueba (ORIGINAL)</td>
                <td>{test_size} √ó 6</td>
            </tr>
            <tr>
                <td><strong>data/y_style_*.npy</strong></td>
                <td>Etiquetas de estilos (3 archivos)</td>
                <td>Para clasificaci√≥n</td>
            </tr>
            <tr>
                <td><strong>data/y_quality_*.npy</strong></td>
                <td>Scores de calidad (3 archivos)</td>
                <td>Para regresi√≥n</td>
            </tr>
        </table>
    </div>

    <!-- CONCLUSIONES -->
    <div class="section">
        <h2>üéØ Conclusiones</h2>
        
        <div class="conclusiones">
            <h3>‚úÖ Preparaci√≥n Exitosa</h3>
            <ul>
                <li>Dataset ampliado de {train_original_size} a {train_augmented_size} muestras de entrenamiento</li>
                <li>Total de {train_augmented_size + val_size + test_size} muestras en todos los conjuntos</li>
                <li>6 caracter√≠sticas por muestra (4 originales + 2 creadas)</li>
                <li>2 objetivos: clasificaci√≥n (estilo) + regresi√≥n (score calidad)</li>
                <li>Datos normalizados y perfectamente balanceados</li>
                <li>Divisi√≥n estratificada manteniendo proporciones</li>
            </ul>
        </div>

        <div class="conclusiones">
            <h3>üöÄ Ventajas de esta Preparaci√≥n</h3>
            <ul>
                <li><strong>M√°s datos de entrenamiento:</strong> {train_augmented_size/train_original_size:.1f}x m√°s muestras para aprender patrones</li>
                <li><strong>Mejor generalizaci√≥n:</strong> Reduce riesgo de overfitting</li>
                <li><strong>Resultados m√°s estables:</strong> Menor varianza entre entrenamientos</li>
                <li><strong>Acad√©micamente s√≥lido:</strong> SMOTE es pr√°ctica est√°ndar reconocida</li>
            </ul>
        </div>

        </div>

    <div class="footer">
        <p>üç∫ Sistema de Control de Calidad Cervecero - Valdivia, Chile</p>
        <p>Fase 2: Preparaci√≥n de Datos con SMOTE 2x</p>
        <p>Noviembre 2025</p>
    </div>
</body>
</html>
"""

with open('REPORTE_PREPARACION_DATOS.html', 'w', encoding='utf-8') as f:
    f.write(html_content)

print("\n‚úÖ Reporte HTML generado: REPORTE_PREPARACION_DATOS.html")

# ============================================
# PASO 10: RESUMEN FINAL
# ============================================

print("\n" + "="*70)
print("üìã RESUMEN DE LA PREPARACI√ìN DE DATOS")
print("="*70)

print(f"""
‚úÖ PROCESAMIENTO COMPLETADO CON SMOTE 2x

üìä Caracter√≠sticas:
   ‚Ä¢ Variables originales: 4 (OG, ABV, pH, IBU)
   ‚Ä¢ Variables creadas: 2 (ABV_OG_ratio, IBU_ABV_ratio)
   ‚Ä¢ TOTAL: 6 caracter√≠sticas

üéØ Targets:
   ‚Ä¢ Clasificaci√≥n: 3 estilos (Premium Lager, IPA, Light Lager)
   ‚Ä¢ Regresi√≥n: Score de calidad (0-1)

üì¶ Divisi√≥n de datos:
   ‚Ä¢ Train ORIGINAL: {train_original_size} muestras
   ‚Ä¢ Train CON SMOTE 2x: {train_augmented_size} muestras (+{incremento})
   ‚Ä¢ Validation: {val_size} muestras (sin augmentation)
   ‚Ä¢ Test: {test_size} muestras (sin augmentation)

üîÑ Data Augmentation:
   ‚Ä¢ T√©cnica: SMOTE 2x
   ‚Ä¢ Muestras a√±adidas: {incremento} ({incremento/train_original_size*100:.1f}%)
   ‚Ä¢ Factor: {train_augmented_size/train_original_size:.2f}x

üíæ Archivos generados:
   ‚Ä¢ scaler.pkl (StandardScaler)
   ‚Ä¢ label_encoder.pkl (codificador de estilos)
   ‚Ä¢ Carpeta data/ con todos los conjuntos (9 archivos .npy)
   ‚Ä¢ REPORTE_PREPARACION_DATOS.html

""")

print("="*70)